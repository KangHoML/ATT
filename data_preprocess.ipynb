{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_structure(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        print(f\"파일명: {os.path.basename(file_path)}\")\n",
    "        print(f\"데이터 타입: {type(data)}\")\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            print(\"키 구조:\")\n",
    "            structure = []\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, list) and len(value) > 0:\n",
    "                    sub_structure = get_structure(value[0])\n",
    "                    for sub_key, sub_type in sub_structure:\n",
    "                        structure.append([f\"{key}.{sub_key}\", sub_type])\n",
    "                elif isinstance(value, dict):\n",
    "                    sub_structure = get_structure(value)\n",
    "                    for sub_key, sub_type in sub_structure:\n",
    "                        structure.append([f\"{key}.{sub_key}\", sub_type])\n",
    "                else:\n",
    "                    structure.append([key, type(value).__name__])\n",
    "            \n",
    "            df = pd.DataFrame(structure, columns=['키', '타입'])\n",
    "            print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "            \n",
    "            print(\"\\n데이터 샘플:\")\n",
    "            if 'data' in data and isinstance(data['data'], list) and len(data['data']) > 0:\n",
    "                sample = data['data'][0]\n",
    "                df_sample = pd.DataFrame([sample])\n",
    "                print(tabulate(df_sample, headers='keys', tablefmt='pretty', showindex=False))\n",
    "        \n",
    "        elif isinstance(data, list):\n",
    "            print(f\"리스트 길이: {len(data)}\")\n",
    "            if len(data) > 0:\n",
    "                print(\"첫 번째 항목 구조:\")\n",
    "                structure = get_structure(data[0])\n",
    "                df = pd.DataFrame(structure, columns=['키', '타입'])\n",
    "                print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "                \n",
    "                print(\"\\n데이터 샘플:\")\n",
    "                df_sample = pd.DataFrame([data[0]])\n",
    "                print(tabulate(df_sample, headers='keys', tablefmt='pretty', showindex=False))\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n",
    "def get_structure(obj, prefix=''):\n",
    "    structure = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            new_key = f\"{prefix}.{k}\" if prefix else k\n",
    "            if isinstance(v, (dict, list)):\n",
    "                structure.extend(get_structure(v, new_key))\n",
    "            else:\n",
    "                structure.append([new_key, type(v).__name__])\n",
    "    elif isinstance(obj, list) and len(obj) > 0:\n",
    "        structure.extend(get_structure(obj[0], prefix))\n",
    "    else:\n",
    "        structure.append([prefix, type(obj).__name__])\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일들이 있는 디렉토리 경로\n",
    "train_path = '../datasets/KoreanError/Training/labelled_data/'\n",
    "valid_path = '../datasets/KoreanError/Validation/labelled_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명: 띄어쓰기문장부호오류.json\n",
      "데이터 타입: <class 'dict'>\n",
      "키 구조:\n",
      "+--------------------------------------+------+\n",
      "|                  키                  | 타입 |\n",
      "+--------------------------------------+------+\n",
      "|           info.description           | str  |\n",
      "|            info.data_name            | str  |\n",
      "|        info.data_description         | str  |\n",
      "|             info.creator             | str  |\n",
      "|           info.distributor           | str  |\n",
      "|             info.version             | str  |\n",
      "|        data.metadata_info.id         | str  |\n",
      "|      data.metadata_info.source       | str  |\n",
      "|     data.annotation.err_sentence     | str  |\n",
      "|  data.annotation.err_sentence_spell  | str  |\n",
      "|     data.annotation.cor_sentence     | str  |\n",
      "|  data.annotation.cor_sentence_spell  | str  |\n",
      "|    data.annotation.errors.err_idx    | int  |\n",
      "| data.annotation.errors.err_location  | int  |\n",
      "|   data.annotation.errors.err_text    | str  |\n",
      "|   data.annotation.errors.cor_text    | str  |\n",
      "|  data.annotation.errors.err_details  | str  |\n",
      "| data.annotation.errors.edit_distance | int  |\n",
      "|             data.dataset             | str  |\n",
      "|             data._error1             | int  |\n",
      "+--------------------------------------+------+\n",
      "\n",
      "데이터 샘플:\n",
      "+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                  metadata_info                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                              annotation                                                                                                                                                                                                                                                                                                                                                                                                                                                               | dataset |                                                                                                                                                                                                  _error1                                                                                                                                                                                                   |\n",
      "+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| {'id': 'ext0000000026818', 'source': '뉴스기사'} | {'err_sentence': '일손과시간이부족해 검증을 다못했다는 군색한변명은안통한다', 'err_sentence_spell': '일손과시간이부족해 검증을 다못했다는 군색한변명은안통한다', 'cor_sentence': '일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다.', 'cor_sentence_spell': '일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다.', 'errors': [{'err_idx': 0, 'err_location': 0, 'err_text': '일손과시간이부족해', 'cor_text': '일손과 시간이 부족해', 'err_details': ['띄어쓰기'], 'edit_distance': 2}, {'err_idx': 1, 'err_location': 2, 'err_text': '다못했다는', 'cor_text': '다 못했다는', 'err_details': ['띄어쓰기'], 'edit_distance': 1}, {'err_idx': 2, 'err_location': 3, 'err_text': '군색한변명은안통한다', 'cor_text': '군색한 변명은 안 통한다.', 'err_details': ['띄어쓰기', '문장부호'], 'edit_distance': 4}]} |  spac   | [[2, [0, 1], [0, 3], ['일손과시간이부족해'], ['일손과', '시간이', '부족해'], [['insert', ' '], ['insert', ' ']]], [0, [1, 2], [3, 4], ['검증을'], ['검증을'], []], [1, [2, 3], [4, 6], ['다못했다는'], ['다', '못했다는'], [['insert', ' ']]], [4, [3, 4], [5, 9], ['군색한변명은안통한다'], ['군색한', '변명은', '안', '통한다.'], [['insert', ' '], ['insert', ' '], ['insert', ' '], ['insert', '.']]]] |\n",
      "+--------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training 데이터의 구조 확인\n",
    "for filename in os.listdir(train_path):\n",
    "    if filename.endswith('.json'):\n",
    "        print_structure(os.path.join(train_path, filename))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명: 띄어쓰기문장부호오류.json\n",
      "데이터 타입: <class 'dict'>\n",
      "키 구조:\n",
      "+--------------------------------------+------+\n",
      "|                  키                  | 타입 |\n",
      "+--------------------------------------+------+\n",
      "|           info.description           | str  |\n",
      "|            info.data_name            | str  |\n",
      "|        info.data_description         | str  |\n",
      "|             info.creator             | str  |\n",
      "|           info.distributor           | str  |\n",
      "|             info.version             | str  |\n",
      "|        data.metadata_info.id         | str  |\n",
      "|      data.metadata_info.source       | str  |\n",
      "|     data.annotation.err_sentence     | str  |\n",
      "|  data.annotation.err_sentence_spell  | str  |\n",
      "|     data.annotation.cor_sentence     | str  |\n",
      "|  data.annotation.cor_sentence_spell  | str  |\n",
      "|    data.annotation.errors.err_idx    | int  |\n",
      "| data.annotation.errors.err_location  | int  |\n",
      "|   data.annotation.errors.err_text    | str  |\n",
      "|   data.annotation.errors.cor_text    | str  |\n",
      "|  data.annotation.errors.err_details  | str  |\n",
      "| data.annotation.errors.edit_distance | int  |\n",
      "|             data.dataset             | str  |\n",
      "|             data._error1             | int  |\n",
      "+--------------------------------------+------+\n",
      "\n",
      "데이터 샘플:\n",
      "+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                   metadata_info                    |                                                                                                                                                                                                           annotation                                                                                                                                                                                                           | dataset |                                                                                  _error1                                                                                  |\n",
      "+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| {'id': 'ext0000000013451', 'source': '자유게시판'} | {'err_sentence': '나도이제서울대간다는건가?', 'err_sentence_spell': '나도이제서울대간다는건가?', 'cor_sentence': '나도 이제 서울대 간다는 건가?', 'cor_sentence_spell': '나도 이제 서울대 간다는 건가?', 'errors': [{'err_idx': 0, 'err_location': 0, 'err_text': '나도이제서울대간다는건가?', 'cor_text': '나도 이제 서울대 간다는 건가?', 'err_details': ['띄어쓰기'], 'edit_distance': 4}]} |  spac   | [[4, [0, 1], [0, 5], ['나도이제서울대간다는건가?'], ['나도', '이제', '서울대', '간다는', '건가?'], [['insert', ' '], ['insert', ' '], ['insert', ' '], ['insert', ' ']]]] |\n",
      "+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation 데이터의 구조 확인\n",
    "for filename in os.listdir(valid_path):\n",
    "    if filename.endswith('.json'):\n",
    "        print_structure(os.path.join(valid_path, filename))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_sentecne와 cor_sentence만 뽑아서 데이터 구성\n",
    "def extract_sents(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    extracted_data = []\n",
    "    for item in data['data']:\n",
    "        extracted_item = {\n",
    "            'err_sentence': item['annotation']['err_sentence'],\n",
    "            'cor_sentence': item['annotation']['cor_sentence']\n",
    "        }\n",
    "        extracted_data.append(extracted_item)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(extracted_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../datasets/KoreanError/Training\"\n",
    "valid_dir = \"../datasets/KoreanError/Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 json파일에 대해서 처리 (train)\n",
    "for filename in os.listdir(train_path):\n",
    "    if filename.endswith('.json'):\n",
    "        input_file = os.path.join(train_path, filename)\n",
    "        output_file = os.path.join(train_dir, f'{filename}')\n",
    "        extract_sents(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 json파일에 대해서 처리 (valid)\n",
    "for filename in os.listdir(valid_path):\n",
    "    if filename.endswith('.json'):\n",
    "        input_file = os.path.join(valid_path, filename)\n",
    "        output_file = os.path.join(valid_dir, f'{filename}')\n",
    "        extract_sents(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_json_files(input_dir, output_file):\n",
    "    merged_data = []\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            file_id = os.path.splitext(filename)[0]  # 파일 확장자를 제외한 이름\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for item in data:\n",
    "                    new_item = OrderedDict([\n",
    "                        ('id', file_id),\n",
    "                        ('err_sentence', item['err_sentence']),\n",
    "                        ('cor_sentence', item['cor_sentence'])\n",
    "                    ])\n",
    "                    merged_data.append(new_item)\n",
    "\n",
    "    # 병합된 데이터를 새 파일에 저장\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return len(merged_data)  # 총 데이터 수 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Length : 214300, Validation Data Length : 29050\n"
     ]
    }
   ],
   "source": [
    "# train, validation 개수와 함께 출력\n",
    "train_len = merge_json_files(train_dir, os.path.join(train_dir, \"train_data.json\"))\n",
    "valid_len = merge_json_files(valid_dir, os.path.join(valid_dir, \"valid_data.json\"))\n",
    "\n",
    "print(f\"Training Data Length : {train_len}, Validation Data Length : {valid_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
